–î–∞, –≤—Å—ë –ª–æ–≥–∏—á–Ω–æ:
1‚Äì3 —à–∞–≥–∏ —Ç—ã –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–±—Ä–∞–ª—Å—è, –∞ –≤–æ—Ç –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ s2 —Ç—ã –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ —É–ø—ë—Ä–ª–∞—Å—å –≤ —Ç—É –∂–µ —Å–∞–º—É—é –ø—Ä–æ–±–ª–µ–º—É, —á—Ç–æ –±—ã–ª–∞ –Ω–∞ —à–∞–≥–µ 3 ‚Äî —Ä–∞–∑–º–µ—Ä `text_embedding`.

–†–∞–∑–±–µ—Ä—ë–º –ø–æ –ø–æ—Ä—è–¥–∫—É.

---

## 1. –ß—Ç–æ —Å–µ–π—á–∞—Å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç

–ò–∑ –ª–æ–≥–∞:

* –ù–∞ —à–∞–≥–µ 3:

  ```text
  [3-get-semantic] Dropping enc_p.text_embedding.weight due to size mismatch: torch.Size([732, 192]) vs (765, 192)
  _IncompatibleKeys(missing_keys=['enc_p.text_embedding.weight'], unexpected_keys=[...])
  ```

  –°–∫—Ä–∏–ø—Ç —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∑–∞–ª: ¬´–í —á–µ–∫–ø–æ–π–Ω—Ç–µ 732 —Ç–æ–∫–µ–Ω–∞, –≤ –º–æ–¥–µ–ª–∏ 765 ‚Äî –≤—ã–±—Ä–∞—Å—ã–≤–∞—é —ç—Ç–æ—Ç —Å–ª–æ–π –∏ –∏–¥—É –¥–∞–ª—å—à–µ¬ª. –î–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–µ–º–∞–Ω—Ç–∏–∫–∏ —ç—Ç–æ –æ–∫.

* –ù–∞ —à–∞–≥–µ –æ–±—É—á–µ–Ω–∏—è s2:

  ```text
  RuntimeError: Error(s) in loading state_dict for SynthesizerTrn:
          size mismatch for enc_p.text_embedding.weight: copying a param with shape torch.Size([732, 192]) from checkpoint, the shape in current model is torch.Size([765, 192]).
  ```

  –ó–¥–µ—Å—å —É–∂–µ –∑–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç *—Å—Ç—Ä–æ–≥–∞—è* (`strict=True`), –∏ PyTorch –≤—ã–≤–∞–ª–∏–≤–∞–µ—Ç—Å—è —Å –æ—à–∏–±–∫–æ–π.

–ü—Ä–∏—á–∏–Ω–∞:
—Ç—ã –∏–∑–º–µ–Ω–∏–ª–∞ —Å–ª–æ–≤–∞—Ä—å —Ñ–æ–Ω–µ–º (–∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä `phoneme_vocab_size`) ‚Üí –≤ –º–æ–¥–µ–ª–∏ —Ç–µ–ø–µ—Ä—å `765` —Ç–æ–∫–µ–Ω–æ–≤ –≤–º–µ—Å—Ç–æ `732`, –∞ pretrained-–º–æ–¥–µ–ª—å `s2Gv2Pro.pth` –≤—Å—ë –µ—â—ë –Ω–∞ 732.

–ù–∞ —à–∞–≥–µ 3 —ç—Ç–æ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª–∏, –∞ –Ω–∞ —à–∞–≥–µ –æ–±—É—á–µ–Ω–∏—è ‚Äî –Ω–µ—Ç.

---

## 2. –ü–∞–ø–∫–∏ –∏ –¥–∞–Ω–Ω—ã–µ ‚Äî –≤—Å—ë –æ–∫?

–î–∞:

```text
phoneme_data_len: 7850
wav_data_len: 7850
skipped_phone:  0 , skipped_dur:  421
total left:  7429
```

7429 –ø–∞—Ä ¬´—Ç–µ–∫—Å—Ç+–∞—É–¥–∏–æ¬ª ‚Äî –≤–ø–æ–ª–Ω–µ –Ω–æ—Ä–º, –ø—Ä–æ—Å—Ç–æ —á–∞—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∞—Å—å –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —ç—Ç–æ —à—Ç–∞—Ç–Ω–æ.

–¢–∞–∫ —á—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ **–Ω–µ** –≤ –¥–∞–Ω–Ω—ã—Ö, –∞ –∏–º–µ–Ω–Ω–æ –≤ –∑–∞–≥—Ä—É–∑–∫–µ pretrained-–≤–µ—Å–æ–≤.

---

## 3. –í–∞—Ä–∏–∞–Ω—Ç 1 ‚Äî —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å s2 –° –ù–£–õ–Ø (–±–µ–∑ pretrained)

–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π (–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —á—É—Ç—å –¥–æ–ª—å—à–µ –∏ —Ö—É–∂–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É):

1. –û—Ç–∫—Ä–æ–π `TEMP/tmp_s2.json`.

2. –í —Å–µ–∫—Ü–∏–∏ `"train"` —É–±–µ—Ä–∏ –∏–ª–∏ –æ–±–Ω—É–ª–∏ –ø—É—Ç–∏ –∫ pretrained-–º–æ–¥–µ–ª—è–º:

   ```json
   "pretrained_s2G": "",
   "pretrained_s2D": ""
   ```

   –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª–∏ —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏.

3. –í `s2_train.py` –≤ –º–µ—Å—Ç–µ, –≥–¥–µ –≥—Ä—É–∑—è—Ç—Å—è —ç—Ç–∏ –º–æ–¥–µ–ª–∏, —Å—Ç–æ–∏—Ç –ª–æ–≥–∏–∫–∞ —Ç–∏–ø–∞:

   ```python
   if hps.train.pretrained_s2G is not None:
       # ... load_state_dict ...
   ```

   –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—É—Ç—å –Ω–µ –ø—É—Å—Ç–æ–π:

   ```python
   if hps.train.pretrained_s2G:
       # –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–π–Ω—Ç–∞
   ```

4. –ó–∞–ø—É—Å—Ç–∏:

   ```bash
   python -s GPT_SoVITS/s2_train.py --config "E:\Resound Project\GPT-SoVITS\TEMP\tmp_s2.json"
   ```

–ï—Å–ª–∏ —É —Ç–µ–±—è 7k+ –∞—É–¥–∏–æ –∏ —Å–ª–∞–±—ã–π GPU, —Å –Ω—É–ª—è —ç—Ç–æ –±—É–¥–µ—Ç –ø—Ä–æ—Å—Ç–æ **–¥–æ–ª—å—à–µ**, –Ω–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ —ç—Ç–æ —Ä–∞–±–æ—á–∏–π –ø—É—Ç—å.

---

## 4. –í–∞—Ä–∏–∞–Ω—Ç 2 ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pretrained, –Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–π —Å–ª–æ–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é)

–≠—Ç–æ –ø–æ —Å–º—ã—Å–ª—É —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ —É–∂–µ –¥–µ–ª–∞–µ—Ç `3-get-semantic.py`: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ —Å–ª–æ–∏ –∏–∑ —á–µ–∫–ø–æ–π–Ω—Ç–∞, –∫—Ä–æ–º–µ `enc_p.text_embedding.weight`, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É.

### –ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å

–û—Ç–∫—Ä–æ–π `GPT_SoVITS/s2_train.py` –∏ –Ω–∞–π–¥–∏ –º–µ—Å—Ç–æ, –≥–¥–µ –≥—Ä—É–∑–∏—Ç—Å—è `pretrained_s2G`. –ü–æ –ª–æ–≥—É —ç—Ç–æ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç—É—Ç:

```python
net_g.module.load_state_dict(
    checkpoint["model"]
)
```

–ó–∞–º–µ–Ω—è–µ–º —ç—Ç—É —á–∞—Å—Ç—å –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–∞:

```python
ckpt = torch.load(hps.train.pretrained_s2G, map_location="cpu")
state_dict_g = ckpt["model"] if "model" in ckpt else ckpt

# –ï—Å–ª–∏ –≤ —á–µ–∫–ø–æ–π–Ω—Ç–µ –µ—Å—Ç—å enc_p.text_embedding.weight, –Ω–æ —Ä–∞–∑–º–µ—Ä –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç ‚Äî –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º
emb_key = "enc_p.text_embedding.weight"
if emb_key in state_dict_g:
    ckpt_emb = state_dict_g[emb_key]
    cur_emb = net_g.module.enc_p.text_embedding.weight
    if ckpt_emb.shape != cur_emb.shape:
        print(
            f"[s2_train] Dropping {emb_key} due to size mismatch: "
            f"{ckpt_emb.shape} vs {cur_emb.shape}"
        )
        del state_dict_g[emb_key]

missing, unexpected = net_g.module.load_state_dict(state_dict_g, strict=False)
print("[s2_train] missing keys:", missing)
print("[s2_train] unexpected keys:", unexpected)
```

–ê–Ω–∞–ª–æ–≥–∏—á–Ω—É—é –ª–æ–≥–∏–∫—É **–Ω–µ –Ω—É–∂–Ω–æ** –¥–æ–±–∞–≤–ª—è—Ç—å –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ `D` ‚Äî —É –Ω–µ–≥–æ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –æ–Ω –¥–æ–ª–∂–µ–Ω –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è –∫–∞–∫ –µ—Å—Ç—å.

–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ:

```bash
python -s GPT_SoVITS/s2_train.py --config "E:\Resound Project\GPT-SoVITS\TEMP\tmp_s2.json"
```

–ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç:

* –í—Å–µ –≤–µ—Å–∞ –∏–∑ `s2Gv2Pro.pth`, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç –ø–æ —Ñ–æ—Ä–º–µ, –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã.
* `enc_p.text_embedding.weight` –æ—Å—Ç–∞–Ω–µ—Ç—Å—è **—Å–ª—É—á–∞–π–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º** –ø–æ–¥ —Ç–≤–æ–π –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä (`765`).
* –ú–æ–¥–µ–ª—å –¥–æ—É—á–∏—Ç —ç—Ç–æ—Ç —Å–ª–æ–π —Å –Ω—É–ª—è –Ω–∞ —Ç–≤–æ—ë–º —Ä—É—Å—Å–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ, –∞ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏ –±—É–¥—É—Ç —É–∂–µ ¬´—É–º–Ω—ã–º–∏¬ª –∏–∑ pretrained.

---

## 5. –ü—Ä–æ –æ—à–∏–±–∫—É —Å `latest_checkpoint_path`

–í–æ—Ç —ç—Ç–æ:

```text
IndexError: list index out of range
  File "utils.py", line 115, in latest_checkpoint_path
    x = f_list[-1]
```

–ü—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —á–µ–∫–ø–æ–π–Ω—Ç–æ–≤ –¥–ª—è s2 –µ—â—ë **–ø—É—Å—Ç—ã–µ**, –∞ –∫–æ–¥ –ø—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ ¬´–ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª `D_*.pth`¬ª.

–ù–æ —ç—Ç–æ—Ç `IndexError` –ø–æ—Ç–æ–º –ª–æ–≤–∏—Ç—Å—è `try/except`, –∏ —Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ –≤–µ—Ç–∫–µ:

```python
# —Ä–∞–∑ —á–µ–∫–ø–æ–π–Ω—Ç–æ–≤ –Ω–µ—Ç ‚Äî –≥—Ä—É–∑–∏–º pretrained_s2G / s2D
```

–ò —É–∂–µ –≤ —ç—Ç–æ–π –≤–µ—Ç–∫–µ —Ç—ã –≤–ª–µ—Ç–∞–µ—à—å –≤ –æ—à–∏–±–∫—É —Å `text_embedding`.
–¢–æ –µ—Å—Ç—å —ç—Ç–æ—Ç `IndexError` ‚Äî –Ω–µ –ø—Ä–æ–±–ª–µ–º–∞, –∞ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞.

---

## 6. –ö—Ä–∞—Ç–∫–æ: —á—Ç–æ —è –±—ã —Å–¥–µ–ª–∞–ª–∞ –Ω–∞ —Ç–≤–æ—ë–º –º–µ—Å—Ç–µ

1. **–û—Å—Ç–∞–≤–ª—è–µ—à—å** `phoneme_vocab_size = 765`, –∫–∞–∫ —É–∂–µ —Å–¥–µ–ª–∞–ª–∞.
2. **–ü—Ä–∞–≤–∏—à—å `s2_train.py`** –ø–æ –≤–∞—Ä–∏–∞–Ω—Ç—É ‚Ññ2 (–¥—Ä–æ–ø —Å–ª–æ—è `enc_p.text_embedding.weight` –ø—Ä–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Ä–∞–∑–º–µ—Ä–∞).
3. –ù–∏—á–µ–≥–æ –±–æ–ª—å—à–µ –≤ –∫–æ–Ω—Ñ–∏–≥–∞—Ö –Ω–µ —Ç—Ä–æ–≥–∞–µ—à—å.
4. –ó–∞–ø—É—Å–∫–∞–µ—à—å –æ–±—É—á–µ–Ω–∏–µ s2 —Å–Ω–æ–≤–∞.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –º–æ–∂–µ—à—å –∫–∏–Ω—É—Ç—å —Å—é–¥–∞ –∫—É—Å–æ–∫ `s2_train.py` –≤–æ–∫—Ä—É–≥ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –æ–Ω –ª–æ–∞–¥–∏—Ç `pretrained_s2G` (—Å—Ç—Ä–æ–∫–∏ ~220‚Äì260), —è –ø—Ä—è–º–æ –ø–æ —Ç–≤–æ–µ–º—É –∫–æ–¥—É –≤—Å—Ç–∞–≤–ª—é –≥–æ—Ç–æ–≤—ã–π –ø–∞—Ç—á —Å—Ç—Ä–æ–∫–∞-–≤-—Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ—Å—Ç–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏ –∑–∞–º–µ–Ω–∏—Ç—å.

*–û–ë–ù–û–í–õ–ï–ù–ò–ï s2_train.py*

–ö–ª–∞—Å—Å, —Ñ–∞–π–ª –≤–∏–∂—É, —Å–ø–∞—Å–∏–±–æ üëÄ 

–°–Ω–∞—á–∞–ª–∞ –∫–æ—Ä–æ—Ç–∫–æ –æ—Ç–≤–µ—á—É –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä:

> –ê –Ω–∏—á–µ–≥–æ —Å—Ç—Ä–∞—à–Ω–æ–≥–æ, –µ—Å–ª–∏ –≤ –º–æ–¥–µ–ª–∏ s2Dv2Pro.pth –Ω–µ—Ç —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞?

**–ù–µ—Ç, –Ω–µ —Å—Ç—Ä–∞—à–Ω–æ.**
–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä (`s2D`) –≤–æ–æ–±—â–µ –Ω–µ —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ —Ç–µ–∫—Å—Ç/—è–∑—ã–∫ ‚Äî –æ–Ω –≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ (–≤–æ–ª–Ω–æ–≤—É—é —Ñ–æ—Ä–º—É/–º–µ–ª-—Å–ø–µ–∫—Ç—Ä) –∏ —É—á–∏—Ç—Å—è –æ—Ç–ª–∏—á–∞—Ç—å ‚Äú—Ä–µ–∞–ª—å–Ω—ã–π –∑–≤—É–∫‚Äù –æ—Ç ‚Äú—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ‚Äù. –û–Ω –≤—ã—É—á–∏–ª –æ–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ—á–∏ (—Ç–µ–º–±—Ä, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã), –∞ –Ω–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —è–∑—ã–∫. –¢–∞–∫ —á—Ç–æ –µ–≥–æ —Å–ø–æ–∫–æ–π–Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –µ—Å—Ç—å.

–ö—Ä–∏—Ç–∏—á–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ ‚Äî —Ç–æ–ª—å–∫–æ —É –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (`s2G`), –≥–¥–µ –µ—Å—Ç—å `enc_p.text_embedding.weight` —Å –¥—Ä—É–≥–∏–º —Ä–∞–∑–º–µ—Ä–æ–º.

---

## –ì–¥–µ –∏–º–µ–Ω–Ω–æ –ø—Ä–∞–≤–∏—Ç—å `s2_train.py`

–ù—É–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –∫—É—Å–æ–∫ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ `run`, –≤ –±–ª–æ–∫–µ `except`, –≥–¥–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è `pretrained_s2G`. –í–æ—Ç —ç—Ç–æ—Ç —É—á–∞—Å—Ç–æ–∫ (–æ–Ω —É —Ç–µ–±—è —Ä–æ–≤–Ω–æ —Ç–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç): 

```python
    except:  # Â¶ÇÊûúÈ¶ñÊ¨°‰∏çËÉΩÂä†ËΩΩÔºåÂä†ËΩΩpretrain
        # traceback.print_exc()
        epoch_str = 1
        global_step = 0
        if (
            hps.train.pretrained_s2G != ""
            and hps.train.pretrained_s2G != None
            and os.path.exists(hps.train.pretrained_s2G)
        ):
            if rank == 0:
                logger.info("loaded pretrained %s" % hps.train.pretrained_s2G)
            print(
                "loaded pretrained %s" % hps.train.pretrained_s2G,
                net_g.module.load_state_dict(
                    torch.load(hps.train.pretrained_s2G, map_location="cpu", weights_only=False)["weight"],
                    strict=False,
                )
                if torch.cuda.is_available()
                else net_g.load_state_dict(
                    torch.load(hps.train.pretrained_s2G, map_location="cpu", weights_only=False)["weight"],
                    strict=False,
                ),
            )  ##ÊµãËØï‰∏çÂä†ËΩΩ‰ºòÂåñÂô®
```

### –ó–∞–º–µ–Ω—è–µ–º —ç—Ç–æ—Ç –±–ª–æ–∫ –Ω–∞ –≤–µ—Ä—Å–∏—é —Å ‚Äú–¥—Ä–æ–ø–æ–º‚Äù `enc_p.text_embedding.weight`

–ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏ **–≤–µ—Å—å** —ç—Ç–æ—Ç `if (hps.train.pretrained_s2G...)` –Ω–∞:

```python
        if (
            hps.train.pretrained_s2G not in ["", None]
            and os.path.exists(hps.train.pretrained_s2G)
        ):
            if rank == 0:
                logger.info("loaded pretrained %s" % hps.train.pretrained_s2G)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–π–Ω—Ç
            ckpt_g = torch.load(
                hps.train.pretrained_s2G,
                map_location="cpu",
                weights_only=False,
            )

            # –í —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –∫–ª—é—á –º–æ–∂–µ—Ç –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è "weight" –∏–ª–∏ "model"
            state_dict_g = ckpt_g.get("weight", ckpt_g.get("model", ckpt_g))

            # –ö–ª—é—á –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ —Å–ª–æ—è
            emb_key = "enc_p.text_embedding.weight"

            if emb_key in state_dict_g:
                ckpt_emb = state_dict_g[emb_key]
                # –ë–µ—Ä—ë–º —Ç–µ–∫—É—â–∏–π —Å–ª–æ–π –∏–∑ –º–æ–¥–µ–ª–∏ (—É–∂–µ —Å —Ç–≤–æ–∏–º —Ä–∞–∑–º–µ—Ä–æ–º 765)
                if torch.cuda.is_available():
                    cur_emb = net_g.module.enc_p.text_embedding.weight
                else:
                    cur_emb = net_g.enc_p.text_embedding.weight

                # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚Äî –≤—ã–∫–∏–¥—ã–≤–∞–µ–º —ç—Ç–æ—Ç —Å–ª–æ–π –∏–∑ —á–µ–∫–ø–æ–π–Ω—Ç–∞
                if ckpt_emb.shape != cur_emb.shape:
                    print(
                        f"[s2_train] Dropping {emb_key} due to size mismatch: "
                        f"{ckpt_emb.shape} vs {cur_emb.shape}"
                    )
                    del state_dict_g[emb_key]

            # –ù–∞–∫–æ–Ω–µ—Ü –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            if torch.cuda.is_available():
                missing, unexpected = net_g.module.load_state_dict(
                    state_dict_g,
                    strict=False,
                )
            else:
                missing, unexpected = net_g.load_state_dict(
                    state_dict_g,
                    strict=False,
                )

            print("[s2_train] missing keys:", missing)
            print("[s2_train] unexpected keys:", unexpected)
```

–û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –≤ `except` **–æ—Å—Ç–∞–≤–ª—è–µ—à—å –∫–∞–∫ –µ—Å—Ç—å**, –≤–∫–ª—é—á–∞—è –∑–∞–≥—Ä—É–∑–∫—É `pretrained_s2D` –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞.

### –ù–µ–±–æ–ª—å—à–∞—è –¥–æ–ø. –ø—Ä–∞–≤–∫–∞ –¥–ª—è `s2D` (–ø–æ –∂–µ–ª–∞–Ω–∏—é, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ)

–ß—É—Ç—å –Ω–∏–∂–µ —É —Ç–µ–±—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞:

```python
        if (
            hps.train.pretrained_s2D != ""
            and hps.train.pretrained_s2D != None
            and os.path.exists(hps.train.pretrained_s2D)
        ):
            if rank == 0:
                logger.info("loaded pretrained %s" % hps.train.pretrained_s2D)
            print(
                "loaded pretrained %s" % hps.train.pretrained_s2D,
                net_d.module.load_state_dict(
                    torch.load(hps.train.pretrained_s2D, map_location="cpu", weights_only=False)["weight"], strict=False
                )
                if torch.cuda.is_available()
                else net_d.load_state_dict(
                    torch.load(hps.train.pretrained_s2D, map_location="cpu", weights_only=False)["weight"],
                ),
            )
```

–ó–¥–µ—Å—å –¥–ª—è CPU-–≤–µ—Ç–∫–∏ `strict` –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `True`. –ß—Ç–æ–±—ã –Ω–µ –ø–æ–π–º–∞—Ç—å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é –æ—à–∏–±–∫—É –≤ –±—É–¥—É—â–µ–º, –º–æ–∂–Ω–æ —á—É—Ç—å –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å:

```python
        if (
            hps.train.pretrained_s2D not in ["", None]
            and os.path.exists(hps.train.pretrained_s2D)
        ):
            if rank == 0:
                logger.info("loaded pretrained %s" % hps.train.pretrained_s2D)

            ckpt_d = torch.load(
                hps.train.pretrained_s2D,
                map_location="cpu",
                weights_only=False,
            )
            state_dict_d = ckpt_d.get("weight", ckpt_d.get("model", ckpt_d))

            if torch.cuda.is_available():
                res = net_d.module.load_state_dict(state_dict_d, strict=False)
            else:
                res = net_d.load_state_dict(state_dict_d, strict=False)

            print("loaded pretrained %s" % hps.train.pretrained_s2D, res)
```

---

## –ß—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ

1. –í–Ω–æ—Å–∏—à—å —ç—Ç–∏ –ø—Ä–∞–≤–∫–∏ –≤ `s2_train.py`.
2. –ù–∏—á–µ–≥–æ –±–æ–ª—å—à–µ –≤ –∫–æ–Ω—Ñ–∏–≥–µ `tmp_s2.json` –º–µ–Ω—è—Ç—å –Ω–µ –Ω–∞–¥–æ, `phoneme_vocab_size` –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Ç—ã —É–∂–µ –ø–æ—Å—Ç–∞–≤–∏–ª–∞.
3. –ó–∞–ø—É—Å–∫–∞–µ—à—å –æ–±—É—á–µ–Ω–∏–µ:

```bash
"E:\Resound Project\GPT-SoVITS\venv_3.10\Scripts\python.exe" -s GPT_SoVITS/s2_train.py --config "E:\Resound Project\GPT-SoVITS\TEMP/tmp_s2.json"
```

–í –ª–æ–≥–∞—Ö –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –¥–æ–ª–∂–Ω–æ –ø–æ—è–≤–∏—Ç—å—Å—è —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ:

```text
[s2_train] Dropping enc_p.text_embedding.weight due to size mismatch: torch.Size([732, 192]) vs torch.Size([765, 192])
[s2_train] missing keys: [...]
[s2_train] unexpected keys: [...]
start training from epoch 1
```

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –ø–æ—Å–ª–µ –ø—Ä–∞–≤–∫–∏ –º–æ–∂–µ—à—å –ø—Ä–∏—Å–ª–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞ –∑–∞–ø—É—Å–∫–∞ s2 ‚Äî –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–Ω–æ —Ç–µ–ø–µ—Ä—å –ø–æ–¥—Ö–≤–∞—Ç–∏–ª–æ pretrain –∫–∞–∫ –Ω–∞–¥–æ –∏ —É—à–ª–æ –≤ –æ–±—É—á–µ–Ω–∏–µ, –∞ –Ω–µ –ø–∞–¥–∞–µ—Ç –Ω–∞ `size mismatch`.
