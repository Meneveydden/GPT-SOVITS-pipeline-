–î–∞, –≤–æ—Ç —ç—Ç–æ —É–∂–µ –Ω–∞—Å—Ç–æ—è—â–∏–π ¬´–Ω–æ–≤—ã–π —è–∑—ã–∫ –≤ GPT-SoVITS¬ª üòÑ
–û—à–∏–±–∫–∞ –ª–æ–≥–∏—á–Ω–∞—è: –º—ã **–ø–æ–º–µ–Ω—è–ª–∏ —Ä–∞–∑–º–µ—Ä –∞–ª—Ñ–∞–≤–∏—Ç–∞**, –∞ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ä—É—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, —É –∫–æ—Ç–æ—Ä–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –±—ã–ª –ø–æ–¥ —Å—Ç–∞—Ä—ã–π —Ä–∞–∑–º–µ—Ä.

–†–∞–∑–±–µ—Ä—ë–º –ø–æ —à–∞–≥–∞–º.

---

## –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç

–°–æ–æ–±—â–µ–Ω–∏–µ:

```text
size mismatch for enc_p.text_embedding.weight: copying a param with shape torch.Size([732, 192]) from checkpoint, the shape in current model is torch.Size([765, 192]).
```

* **732, 192** ‚Äî —ç—Ç–æ —Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤ **–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π s2-–º–æ–¥–µ–ª–∏** (–∏–∑ `pretrained_s2G`), —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π –ø–æ–¥ –∏—Å—Ö–æ–¥–Ω—ã–π –Ω–∞–±–æ—Ä —Å–∏–º–≤–æ–ª–æ–≤ (EN+ZH+JA+KO+YUE).
* **765, 192** ‚Äî —ç—Ç–æ —Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤ **—Ç–≤–æ–µ–π —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏**, —Å–æ–±—Ä–∞–Ω–Ω–æ–π –ø–æ `s2.json` + –Ω–∞—à–∏–º –Ω–æ–≤—ã–º `symbols2.py` —Å —Ä—É—Å—Å–∫–∏–º–∏ –±—É–∫–≤–∞–º–∏.

–ú—ã –∏–∑–º–µ–Ω–∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å–∏–º–≤–æ–ª–æ–≤ ‚Üí `phoneme_vocab_size` –≤—ã—Ä–æ—Å ‚Üí —Å–ª–æ–π `enc_p.text_embedding` —Å—Ç–∞–ª —à–∏—Ä–µ ‚Üí PyTorch —Ä—É–≥–∞–µ—Ç—Å—è, –∫–æ–≥–¥–∞ –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ª–∏—Ç—å –≤ –Ω–µ–≥–æ —Å—Ç–∞—Ä—ã–π –≤–µ—Å.

**–í–∞–∂–Ω–æ:** –Ω–∞ —à–∞–≥–µ `3-get-semantic.py` –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç **—Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ-—á–∞—Å—Ç—å** –º–æ–¥–µ–ª–∏ (VQ-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –ø–æ Hubert-—Å–ø–µ–∫—Ç—Ä–∞–º).
`enc_p.text_embedding` —Ç–∞–º –≤–æ–æ–±—â–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –≤ checkpoint‚Äô–µ –æ–Ω –ª–µ–∂–∏—Ç ‚Äî –∏ –ª–æ–º–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É.

–ó–Ω–∞—á–∏—Ç, –Ω–∞—à —Ö–æ–¥:

> **–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å (–≤—ã–∫–∏–Ω—É—Ç—å) –≤–µ—Å `enc_p.text_embedding.weight` –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞.**

---

## –ß—Ç–æ –Ω–∞–¥–æ —Å–¥–µ–ª–∞—Ç—å –≤ `3-get-semantic.py`

–û—Ç–∫—Ä–æ–π —É —Å–µ–±—è —Ñ–∞–π–ª
`GPT_SoVITS/prepare_datasets/3-get-semantic.py`.

–ù–∞–π–¥–∏ —Ç–∞–º –∫—É—Å–æ–∫, –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —ç—Ç–æ (—É —Ç–µ–±—è —Å–µ–π—á–∞—Å –æ–Ω –¥–∞—ë—Ç –æ—à–∏–±–∫—É):

```python
print(
    vq_model.load_state_dict(
        torch.load(pretrained_s2G, map_location="cpu")["weight"]
    )
)
```

–ò –∑–∞–º–µ–Ω–∏ –µ–≥–æ **—Ü–µ–ª–∏–∫–æ–º** –Ω–∞ —Ç–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç:

```python
state = torch.load(pretrained_s2G, map_location="cpu")
weights = state.get("weight", state)

# –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –≤—ã–∫–∏–¥—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
if "enc_p.text_embedding.weight" in weights:
    w_ckpt = weights["enc_p.text_embedding.weight"]
    w_model = vq_model.enc_p.text_embedding.weight
    if w_ckpt.shape != w_model.shape:
        print(
            "[3-get-semantic] Dropping enc_p.text_embedding.weight due to size mismatch:",
            w_ckpt.shape, "vs", tuple(w_model.shape),
        )
        del weights["enc_p.text_embedding.weight"]

print(vq_model.load_state_dict(weights, strict=False))
```

–°–º—ã—Å–ª:

* –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç.
* –î–æ—Å—Ç–∞—ë–º –∏–∑ –Ω–µ–≥–æ `weights`.
* –ï—Å–ª–∏ –≤ –Ω—ë–º –µ—Å—Ç—å –∫–ª—é—á `enc_p.text_embedding.weight` **–∏** –µ–≥–æ —Ä–∞–∑–º–µ—Ä –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ ‚Äî —É–¥–∞–ª—è–µ–º —ç—Ç–æ—Ç –∫–ª—é—á.
* –û—Å—Ç–∞–ª—å–Ω–æ–µ –≥—Ä—É–∑–∏–º —Å `strict=False` (—á—Ç–æ–±—ã PyTorch –Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–ª –∏–∑-–∑–∞ —Ç–æ–≥–æ, —á—Ç–æ –æ–¥–∏–Ω —Å–ª–æ–π –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è).

–≠—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ:

* –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ –º–æ–¥–µ–ª—å –≤–æ–æ–±—â–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `enc_p.text_embedding` ‚Äî —Ç–æ–ª—å–∫–æ `extract_latent(ssl_content)`; ([Hugging Face][1])
* VQ-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫/–¥–µ–∫–æ–¥–µ—Ä –∏ –ø—Ä–æ—á–∏–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –∏–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–≥–æ –≤–µ—Å–∞.

---

## –ü–æ—á–µ–º—É –ø–æ—Ç–æ–º –≤—Å—ë –Ω–µ —Ä–∞–∑–≤–∞–ª–∏—Ç—Å—è

* **–î–∞—Ç–∞—Å–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫ (`6-name2semantic-*.tsv`)** –Ω—É–∂–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è GPT-—á–∞—Å—Ç–∏.
  –î–ª—è –µ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:

  * HuBERT-—Ñ–∏—á–∏ (`4-cnhubert/*.pt`),
  * s2-–º–æ–¥–µ–ª—å –∫–∞–∫ VQ-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ (`extract_latent`).

  –¢–µ–∫—Å—Ç –≤ —ç—Ç–æ–º —à–∞–≥–µ **–Ω–µ —É—á–∞—Å—Ç–≤—É–µ—Ç**, –∫—Ä–æ–º–µ –∫–∞–∫ –≤ `2-name2text-*.txt`, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å ¬´–∫–∞–∫–æ–π —Ñ–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å¬ª.

* **–¢–æ, —á—Ç–æ `enc_p.text_embedding` –≤ s2-–º–æ–¥–µ–ª–∏ —Ç–µ–ø–µ—Ä—å –±—É–¥–µ—Ç –Ω–æ–≤—ã–º/—Å–ª—É—á–∞–π–Ω—ã–º**, –≤–∞–∂–Ω–æ —É–∂–µ –Ω–∞ —ç—Ç–∞–ø–µ **–æ–±—É—á–µ–Ω–∏—è —Ç–≤–æ–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ s2** (–∫–æ–≥–¥–∞ –±—É–¥–µ—à—å —Ç—Ä–µ–Ω–∏—Ç—å SoVITS –ø–æ–¥ —Ä—É—Å—Å–∫–∏–π). –ò —ç—Ç–æ –æ–∫: –º—ã –≤—Å—ë —Ä–∞–≤–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º—Å—è –¥–æ–æ–±—É—á–∞—Ç—å/–ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –µ—ë –ø–æ–¥ –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å.

---

## –ß—Ç–æ –±—É–¥–µ—Ç –¥–∞–ª—å—à–µ

–ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ —Ç—ã:

1. –ü—Ä–∞–≤–∏—à—å `3-get-semantic.py` –∫–∞–∫ –≤—ã—à–µ.
2. –°–æ—Ö—Ä–∞–Ω—è–µ—à—å.
3. –°–Ω–æ–≤–∞ –∑–∞–ø—É—Å–∫–∞–µ—à—å:

   ```bat
   "E:\Resound Project\GPT-SoVITS\venv_3.10\Scripts\python.exe" -s GPT_SoVITS/prepare_datasets/3-get-semantic.py
   ```

–û–∂–∏–¥–∞–µ–º:

* –ü—Ä–æ–ø–∞–¥–∞–µ—Ç `RuntimeError` –ø—Ä–æ `size mismatch`.
* –í –∫–æ–Ω—Ü–µ –≤ –ª–æ–≥–∞—Ö –ø–æ—è–≤–∏—Ç—Å—è —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ `...` –∏ –≤ –ø–∞–ø–∫–µ `logs/buriy_audiobooks` –ø–æ—è–≤—è—Ç—Å—è —Ñ–∞–π–ª—ã `6-name2semantic-0.tsv` (–∏, –µ—Å–ª–∏ —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π ‚Äî `-1`, `-2`, ...).

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –º–æ–∂–µ—à—å —Å–∫–∏–Ω—É—Ç—å –º–Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20‚Äì30 —Å—Ç—Ä–æ–∫ –ª–æ–≥–∞ ‚Äî —è –ø–æ–¥—Å–∫–∞–∂—É, –≤—Å—ë –ª–∏ –ø—Ä–æ—à–ª–æ –¥–æ –∫–æ–Ω—Ü–∞ –∏ —á—Ç–æ —É —Ç–µ–±—è —Å–µ–π—á–∞—Å –≥–æ—Ç–æ–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (GPT / SoVITS).

[1]: https://huggingface.co/kevinwang676/GPT-SoVITS-v-3/blob/21bd603175cfb13c9a189c6028b0878ea9cc5bc1/GPT_SoVITS/prepare_datasets/3-get-semantic.py "GPT_SoVITS/prepare_datasets/3-get-semantic.py ¬∑ kevinwang676/GPT-SoVITS-v-3 at 21bd603175cfb13c9a189c6028b0878ea9cc5bc1"


–õ–æ–≥–∏–∫–∞ –ø—Ä–æ **‚Äú—Å—Ç–∞—Ä—ã–π —Å–ª–æ–≤–∞—Ä—å 732 + 33 –±—É–∫–≤—ã = 765‚Äù** ‚Äî –∞–±—Å–æ–ª—é—Ç–Ω–æ –≤–µ—Ä–Ω–∞—è, –Ω–æ —Ç—É—Ç –µ—Å—Ç—å –¥–≤–∞ –≤–∞–∂–Ω—ã—Ö ¬´–Ω–æ¬ª:

1. `phoneme_vocab_size` –≤ `s1longer-v2.yaml` –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ **GPT-—á–∞—Å—Ç–∏ (s1)**.
2. –û—à–∏–±–∫–∞ `"size mismatch ... from checkpoint"` —Å–µ–π—á–∞—Å –≤—ã–ª–µ—Ç–∞–µ—Ç –≤ **s2-–º–æ–¥–µ–ª–∏ –Ω–∞ —à–∞–≥–µ 3**, –∏ –Ω–∞ –Ω–µ—ë —Å–º–µ–Ω–∞ `phoneme_vocab_size` –≤ YAML **–≤–æ–æ–±—â–µ –Ω–µ –≤–ª–∏—è–µ—Ç**.

–î–∞–≤–∞–π –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–∞–∑–ª–æ–∂—É.

---

## –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–∞–≤–∫–∞ `phoneme_vocab_size`

`GPT_SoVITS/configs/s1longer-v2.yaml` ‚Üí `phoneme_vocab_size`:

* —ç—Ç–æ —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —Ñ–æ–Ω–µ–º –¥–ª—è **GPT-–º–æ–¥–µ–ª–∏ (s1)**, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ç–æ–º —É—á–∏—Ç—Å—è –Ω–∞ `text ‚Üí semantic`.
* –º—ã —Ä–µ–∞–ª—å–Ω–æ **—É–≤–µ–ª–∏—á–∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å** (–¥–æ–±–∞–≤–∏–ª–∏ 33 –±—É–∫–≤—ã) ‚Üí **–¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–≤–æ–µ–π s1-–º–æ–¥–µ–ª–∏ —ç—Ç–æ —á–∏—Å–ª–æ —Ç–æ—á–Ω–æ –Ω—É–∂–Ω–æ –º–µ–Ω—è—Ç—å** (–∏ –ª—É—á—à–µ –Ω–µ ¬´–Ω–∞ –≥–ª–∞–∑¬ª, –∞ –ø–æ–¥ —Ç–µ–∫—É—â—É—é `len(symbols2.symbols)`).

–¢–æ –µ—Å—Ç—å:

> –î–∞: **–¥–ª—è –±—É–¥—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è s1** `phoneme_vocab_size` –Ω–∞–¥–æ –ø–æ–¥–æ–≥–Ω–∞—Ç—å –ø–æ–¥ –Ω–æ–≤—ã–π `symbols2`.

–ù–æ.

---

## –û—Ç–∫—É–¥–∞ –±–µ—Ä—ë—Ç—Å—è —Ç–µ–∫—É—â–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 3

–û—à–∏–±–∫–∞:

```text
RuntimeError: Error(s) in loading state_dict for SynthesizerTrn:
    size mismatch for enc_p.text_embedding.weight:
    copying a param with shape torch.Size([732, 192]) from checkpoint,
    the shape in current model is torch.Size([765, 192]).
```

–≠—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ `3-get-semantic.py`, –≥–¥–µ:

* —Å–æ–∑–¥–∞—ë—Ç—Å—è **s2-–º–æ–¥–µ–ª—å** `SynthesizerTrn` (SoVITS),
* –µ–π –ø–æ–¥—Å–æ–≤—ã–≤–∞—é—Ç **–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç** `pretrained_s2G`,
* –≤ —ç—Ç–æ–º —á–µ–∫–ø–æ–∏–Ω—Ç–µ —Å–ª–æ–π `enc_p.text_embedding` –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä `[732, 192]` ‚Äî –ø–æ–¥ —Å—Ç–∞—Ä—ã–π —Å–ª–æ–≤–∞—Ä—å,
* –∞ —É —Ç–≤–æ–µ–π —Ç–µ–∫—É—â–µ–π s2-–º–æ–¥–µ–ª–∏ (–∫–æ—Ç–æ—Ä–∞—è –∏–º–ø–æ—Ä—Ç–∏—Ç –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π `symbols2`) —ç—Ç–æ—Ç —Å–ª–æ–π —É–∂–µ `[765, 192]`.

–¢—É—Ç –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:

* `3-get-semantic.py` –≤–æ–æ–±—â–µ –Ω–µ —á–∏—Ç–∞–µ—Ç `s1longer-v2.yaml`.
  –û–Ω —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ **–∫–æ–Ω—Ñ–∏–≥ s2** (–æ–±—ã—á–Ω–æ `configs/s2.json`) + —Ç–≤–æ–π `symbols2.py`.
* –î–∞–∂–µ –µ—Å–ª–∏ —Ç—ã –ø–æ–º–µ–Ω—è–µ—à—å `phoneme_vocab_size` –≤ YAML, **–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç s2 –æ—Ç —ç—Ç–æ–≥–æ –Ω–µ –∏–∑–º–µ–Ω–∏—Ç—Å—è**.
  –û–Ω –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Å –º–∞—Ç—Ä–∏—Ü–µ–π 732√ó192.

–ü–æ—ç—Ç–æ–º—É:

> –û–¥–Ω–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∞–≤–∫–∞ `phoneme_vocab_size = 765` **–Ω–µ —É–±–µ—Ä—ë—Ç –æ—à–∏–±–∫—É `size mismatch`**.
> –û–Ω–∞ –Ω—É–∂–Ω–∞, –Ω–æ **–¥–ª—è –¥—Ä—É–≥–æ–π —á–∞—Å—Ç–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞** (–æ–±—É—á–µ–Ω–∏–µ GPT).

---

## –ü–æ—á–µ–º—É —è –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∞ ¬´–≤—ã–∫–∏–Ω—É—Ç—å¬ª `enc_p.text_embedding.weight`

–ù–∞ —à–∞–≥–µ 3 –Ω–∞–º –Ω—É–∂–Ω–æ –æ—Ç s2-–º–æ–¥–µ–ª–∏ **—Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ-—á–∞—Å—Ç—å** (VQ-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫, `extract_latent`), —á—Ç–æ–±—ã –ø–æ HuBERT-—Ñ–∏—á–∞–º –ø–æ–ª—É—á–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ–∫–µ–Ω—ã –∏ –∑–∞–ø–∏—Å–∞—Ç—å –∏—Ö –≤ `6-name2semantic-*.tsv`.

–°–ª–æ–π `enc_p.text_embedding` ‚Äî —ç—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ s2-–º–æ–¥–µ–ª–∏, –æ–Ω:

* –Ω–∞ —à–∞–≥–µ 3 **–≤–æ–æ–±—â–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è**;
* –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ –µ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ –∫–∞–∫ —á–∞—Å—Ç—å –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏.

–ü–æ—ç—Ç–æ–º—É —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—É—Ç—å:

* –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ `pretrained_s2G` –≤ `3-get-semantic.py`:

  * –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä `enc_p.text_embedding.weight`;
  * –µ—Å–ª–∏ –æ–Ω –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª—å—é ‚Äî —É–¥–∞–ª–∏—Ç—å —ç—Ç–æ—Ç –∫–ª—é—á –∏–∑ `state_dict`;
  * –≥—Ä—É–∑–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ —Å `strict=False`.

–¢–æ –µ—Å—Ç—å —Ç–æ—Ç –ø–∞—Ç—á, –∫–æ—Ç–æ—Ä—ã–π —è –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∞, –∫–∞–∫ —Ä–∞–∑ –≥–æ–≤–æ—Ä–∏—Ç PyTorch‚Äô—É:
*¬´–ù–µ —Ç—Ä–æ–≥–∞–π —ç—Ç–æ—Ç —Å–ª–æ–π, –æ–Ω –Ω–∞–º —Å–µ–π—á–∞—Å –≤–æ–æ–±—â–µ –Ω–µ –Ω—É–∂–µ–Ω¬ª*.

---

## –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–¥–µ–ª–∞—Ç—å **–∏ —Ç–æ, –∏ –¥—Ä—É–≥–æ–µ**

–ò–¥–µ–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Ç–µ–±—è —Å–µ–π—á–∞—Å:

### 1. –ò—Å–ø—Ä–∞–≤–∏—Ç—å —à–∞–≥ 3 (—á—Ç–æ–±—ã –ø–∞–π–ø–ª–∞–π–Ω –¥–æ—à—ë–ª –¥–æ –∫–æ–Ω—Ü–∞)

–í `GPT_SoVITS/prepare_datasets/3-get-semantic.py` –∑–∞–º–µ–Ω–∏—Ç—å –º–µ—Å—Ç–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –Ω–∞ —Ç–∞–∫–æ–µ:

```python
state = torch.load(pretrained_s2G, map_location="cpu")
weights = state.get("weight", state)

# –í—ã–∫–∏–¥—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥, –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
if "enc_p.text_embedding.weight" in weights:
    w_ckpt = weights["enc_p.text_embedding.weight"]
    w_model = vq_model.enc_p.text_embedding.weight
    if w_ckpt.shape != w_model.shape:
        print(
            "[3-get-semantic] Dropping enc_p.text_embedding.weight due to size mismatch:",
            w_ckpt.shape, "vs", tuple(w_model.shape),
        )
        del weights["enc_p.text_embedding.weight"]

print(vq_model.load_state_dict(weights, strict=False))
```

–≠—Ç–æ —Å–Ω–∏–º–µ—Ç **–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —ç—Ç—É –æ—à–∏–±–∫—É** –∏ –¥–∞—Å—Ç —Å–æ–∑–¥–∞—Ç—å `6-name2semantic-0.tsv`.

---

### 2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ‚Äî –¥–∞, –ø–æ–º–µ–Ω—è—Ç—å `phoneme_vocab_size` –≤ `s1longer-v2.yaml`

–¢—É—Ç —Ç—ã –ø—Ä–∞–≤ –ø–æ —Å—É—Ç–∏:

* —Å—Ç–∞—Ä—ã–π —Ä–∞–∑–º–µ—Ä (`732`) –±—ã–ª –ø–æ–¥ —Å—Ç–∞—Ä—ã–π `symbols2`,
* —Å–µ–π—á–∞—Å `symbols2.symbols` —Å—Ç–∞–ª —à–∏—Ä–µ, –Ω—É–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.

–õ—É—á—à–µ –≤—Å–µ–≥–æ:

1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∞–ª–µ–Ω—å–∫–∏–π Python –≤ —Ç–≤–æ—ë–º venv:

   ```python
   from text import symbols2
   print(len(symbols2.symbols))
   ```

2. –ü–æ–ª—É—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –≤–ø–∏—Å–∞—Ç—å –≤ `configs/s1longer-v2.yaml`:

   ```yaml
   phoneme_vocab_size: <—ç—Ç–æ_—á–∏—Å–ª–æ>
   ```

–°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ–Ω–æ –∏ –±—É–¥–µ—Ç `765`, –Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ –ø–æ–º–µ—à–∞–µ—Ç.

–≠—Ç–æ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã:

* –∫–æ–≥–¥–∞ —Ç—ã –±—É–¥–µ—à—å **–æ–±—É—á–∞—Ç—å s1 (GPT)**, –æ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ–∑–¥–∞–≤–∞–ª–∞—Å—å —Å —Ç–µ–º –∂–µ —Ä–∞–∑–º–µ—Ä–æ–º —Å–ª–æ–≤–∞—Ä—è, —á—Ç–æ –∏ `symbols2`.

---

## –ö–æ—Ä–æ—Ç–∫–æ –æ—Ç–≤–µ—Ç –Ω–∞ —Ç–≤–æ—é –º—ã—Å–ª—å

> ¬´–Ø –¥—É–º–∞—é, —á—Ç–æ –Ω–∞–¥–æ –ø–æ–º–µ–Ω—è—Ç—å phoneme_vocab_size, –∏ –≤—Å—ë –¥–æ–ª–∂–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å¬ª

* **phoneme_vocab_size –ø–æ–º–µ–Ω—è—Ç—å ‚Äî –Ω–∞–¥–æ**, –∏–Ω–∞—á–µ s1 –ø–æ—Ç–æ–º –±—É–¥–µ—Ç —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–µ–Ω–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ.
* –ù–æ **–¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π –æ—à–∏–±–∫–∏ –Ω–∞ —à–∞–≥–µ 3 —ç—Ç–æ–≥–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ**: –Ω—É–∂–Ω–æ –µ—â—ë –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–π `enc_p.text_embedding.weight` –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ `pretrained_s2G` (–∏–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç / –æ–±—É—á–∞—Ç—å s2 —Å –Ω—É–ª—è ‚Äî –Ω–æ —ç—Ç–æ —É–∂–µ –¥–æ–ª—å—à–µ).

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –º–æ–∂–µ—à—å —Å–∫–∏–Ω—É—Ç—å –∫—É—Å–æ–∫ `3-get-semantic.py` –≤–æ–∫—Ä—É–≥ —Å—Ç—Ä–æ–∫–∏ 84 ‚Äî —è –ø—Ä—è–º–æ –ø–æ —Ç–≤–æ–µ–º—É —Ñ–∞–π–ª—É –ø–æ–∫–∞–∂—É, –∫—É–¥–∞ –∏–º–µ–Ω–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å –ø–∞—Ç—á, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–∏—à–ª–æ—Å—å –≥–∞–¥–∞—Ç—å.
