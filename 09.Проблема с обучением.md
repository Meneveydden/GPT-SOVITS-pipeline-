Да, всё логично:
1–3 шаги ты прошла успешно, датасет собрался, а вот на обучении s2 ты закономерно упёрлась в ту же самую проблему, что была на шаге 3 — размер `text_embedding`.

Разберём по порядку.

---

## 1. Что сейчас происходит

Из лога:

* На шаге 3:

  ```text
  [3-get-semantic] Dropping enc_p.text_embedding.weight due to size mismatch: torch.Size([732, 192]) vs (765, 192)
  _IncompatibleKeys(missing_keys=['enc_p.text_embedding.weight'], unexpected_keys=[...])
  ```

  Скрипт честно сказал: «В чекпойнте 732 токена, в модели 765 — выбрасываю этот слой и иду дальше». Для подготовки семантики это ок.

* На шаге обучения s2:

  ```text
  RuntimeError: Error(s) in loading state_dict for SynthesizerTrn:
          size mismatch for enc_p.text_embedding.weight: copying a param with shape torch.Size([732, 192]) from checkpoint, the shape in current model is torch.Size([765, 192]).
  ```

  Здесь уже загрузка весов происходит *строгая* (`strict=True`), и PyTorch вываливается с ошибкой.

Причина:
ты изменила словарь фонем (или параметр `phoneme_vocab_size`) → в модели теперь `765` токенов вместо `732`, а pretrained-модель `s2Gv2Pro.pth` всё ещё на 732.

На шаге 3 это проигнорировали, а на шаге обучения — нет.

---

## 2. Папки и данные — всё ок?

Да:

```text
phoneme_data_len: 7850
wav_data_len: 7850
skipped_phone:  0 , skipped_dur:  421
total left:  7429
```

7429 пар «текст+аудио» — вполне норм, просто часть сегментов отфильтровалась по длительности, это штатно.

Так что проблема **не** в данных, а именно в загрузке pretrained-весов.

---

## 3. Вариант 1 — тренировать s2 С НУЛЯ (без pretrained)

Самый простой (но потенциально чуть дольше и хуже по качеству):

1. Открой `TEMP/tmp_s2.json`.

2. В секции `"train"` убери или обнули пути к pretrained-моделям:

   ```json
   "pretrained_s2G": "",
   "pretrained_s2D": ""
   ```

   или просто удали эти строки.

3. В `s2_train.py` в месте, где грузятся эти модели, стоит логика типа:

   ```python
   if hps.train.pretrained_s2G is not None:
       # ... load_state_dict ...
   ```

   Проверь, чтобы загрузка происходила только если путь не пустой:

   ```python
   if hps.train.pretrained_s2G:
       # загрузка чекпойнта
   ```

4. Запусти:

   ```bash
   python -s GPT_SoVITS/s2_train.py --config "E:\Resound Project\GPT-SoVITS\TEMP\tmp_s2.json"
   ```

Если у тебя 7k+ аудио и слабый GPU, с нуля это будет просто **дольше**, но технически это рабочий путь.

---

## 4. Вариант 2 — использовать pretrained, но игнорировать конфликтный слой (рекомендую)

Это по смыслу ровно то, что уже делает `3-get-semantic.py`: использовать все слои из чекпойнта, кроме `enc_p.text_embedding.weight`, который не совпадает по размеру.

### Что нужно сделать

Открой `GPT_SoVITS/s2_train.py` и найди место, где грузится `pretrained_s2G`. По логу это примерно тут:

```python
net_g.module.load_state_dict(
    checkpoint["model"]
)
```

Заменяем эту часть на безопасную загрузку с проверкой размера:

```python
ckpt = torch.load(hps.train.pretrained_s2G, map_location="cpu")
state_dict_g = ckpt["model"] if "model" in ckpt else ckpt

# Если в чекпойнте есть enc_p.text_embedding.weight, но размер не совпадает — выбрасываем
emb_key = "enc_p.text_embedding.weight"
if emb_key in state_dict_g:
    ckpt_emb = state_dict_g[emb_key]
    cur_emb = net_g.module.enc_p.text_embedding.weight
    if ckpt_emb.shape != cur_emb.shape:
        print(
            f"[s2_train] Dropping {emb_key} due to size mismatch: "
            f"{ckpt_emb.shape} vs {cur_emb.shape}"
        )
        del state_dict_g[emb_key]

missing, unexpected = net_g.module.load_state_dict(state_dict_g, strict=False)
print("[s2_train] missing keys:", missing)
print("[s2_train] unexpected keys:", unexpected)
```

Аналогичную логику **не нужно** добавлять для дискриминатора `D` — у него нет текстовых эмбеддингов, он должен загрузиться как есть.

После этого:

```bash
python -s GPT_SoVITS/s2_train.py --config "E:\Resound Project\GPT-SoVITS\TEMP\tmp_s2.json"
```

Что произойдёт:

* Все веса из `s2Gv2Pro.pth`, которые совпадают по форме, будут загружены.
* `enc_p.text_embedding.weight` останется **случайно инициализированным** под твой новый размер (`765`).
* Модель доучит этот слой с нуля на твоём русском датасете, а все остальные слои будут уже «умными» из pretrained.

---

## 5. Про ошибку с `latest_checkpoint_path`

Вот это:

```text
IndexError: list index out of range
  File "utils.py", line 115, in latest_checkpoint_path
    x = f_list[-1]
```

Происходит, потому что директории чекпойнтов для s2 ещё **пустые**, а код пытается найти «последний файл `D_*.pth`».

Но этот `IndexError` потом ловится `try/except`, и скрипт переходит к ветке:

```python
# раз чекпойнтов нет — грузим pretrained_s2G / s2D
```

И уже в этой ветке ты влетаешь в ошибку с `text_embedding`.
То есть этот `IndexError` — не проблема, а просто признак первого запуска.

---

## 6. Кратко: что я бы сделала на твоём месте

1. **Оставляешь** `phoneme_vocab_size = 765`, как уже сделала.
2. **Правишь `s2_train.py`** по варианту №2 (дроп слоя `enc_p.text_embedding.weight` при несоответствии размера).
3. Ничего больше в конфигах не трогаешь.
4. Запускаешь обучение s2 снова.

Если хочешь, можешь кинуть сюда кусок `s2_train.py` вокруг строки, где он лоадит `pretrained_s2G` (строки ~220–260), я прямо по твоему коду вставлю готовый патч строка-в-строку, чтобы можно было просто скопировать и заменить.
