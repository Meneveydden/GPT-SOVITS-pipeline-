Коротко: да, сейчас `ru` **не поддерживается из коробки**, из-за этого у тебя и падает `1-get-text.py`. Нужно либо:

* временно «соврать» скрипту и подменить язык на один из поддерживаемых (en/zh/ja/ko/yue),
* либо по-взрослому добавить полноценную поддержку русского (фонемы + g2p + конфиги), как в вики.

Разберём по шагам, что именно у тебя произошло и что можно сделать **прямо сейчас**.

---

## Что именно ломается

В `GPT_SoVITS/prepare_datasets/1-get-text.py` есть такой кусок: ([huggingface.co][1])

```python
language_v1_to_language_v2 = {
    "ZH": "zh", "zh": "zh",
    "JP": "ja", "jp": "ja", "JA": "ja", "ja": "ja",
    "EN": "en", "en": "en", "En": "en",
    "KO": "ko", "Ko": "ko", "ko": "ko",
    "yue": "yue", "YUE": "yue", "Yue": "yue",
}
...
if language in language_v1_to_language_v2.keys():
    todo.append([wav_name, text, language_v1_to_language_v2.get(language, language)])
else:
    print(f"[Waring] The {language = } of {wav_name} is not supported for training.")
```

У тебя в `.list` стоит `ru`, которого **нет в этом словаре**, поэтому:

1. Все строки с `|ru|` выбрасываются с предупреждением `[Waring] The language = 'ru' ... is not supported for training`.
2. В итоге список `todo` остаётся пустой, `res` — пустой, и WebUI падает на проверке:

```python
assert len("".join(opt)) > 0, process_info(..., "failed")
```

То есть сейчас модель не «умеет» русский не потому, что она прям принципиально против, а потому что текстовый фронтенд и мэппинг языков на него просто не знают кода `ru`.

---

## Быстрый костыль, чтобы оно хотя бы заработало

Если тебе сейчас важно **запустить пайплайн и проверить, что вообще всё работает**, можно сделать костыль:

### Вариант 1. Подменить `ru` → `en` в `.list`

В твоём `.list` сейчас строки вида:

```text
"E:\...\1544b79cf3ff.wav"|1544b79cf3ff|ru|ручники и безоружных в целях самозащиты.
```

Можно массово заменить `|ru|` на `|en|` (любой редактор / маленький скрипт).

Плюсы:

* `1-get-text.py` перестанет ругаться — `en` есть в словаре.
* Пайплайн до конца дойдёт.

Минусы:

* `english.g2p` для кириллицы работать по-нормальному не будет — большую часть символов он, скорей всего, выкинет.
* Фонемы будут мусорные, качество TTS будет так себе. Для «первого запуска» сойдёт, но не для финальной модели.

Чуть улучшенный вариант того же трюка — предварительно **транслитерировать русский текст в латиницу** (например, `привет, как дела` → `privet, kak dela`) и тогда ставить `en`. Тогда английский g2p хотя бы увидит нормальные буквы, и фонемы станут осмысленными.

---

## Правильный путь: добавить полноценную поддержку русского

Если ты хочешь, чтобы модель **по-настоящему тренировалась на русском**, нужно сделать то, что в вики описано как «train new languages» ([GitHub][2]):

### 1. Добавить код языка в `1-get-text.py`

В файл `GPT_SoVITS/prepare_datasets/1-get-text.py` в словарь `language_v1_to_language_v2` добавить:

```python
    "RU": "ru",
    "ru": "ru",
    "Ru": "ru",
```

Это просто скажет скрипту: такие коды существуют, не выбрасывай строки.

### 2. Добавить русский в `cleaner.py`

Сейчас в `GPT_SoVITS/text/cleaner.py` есть карта: ([GitHub][3])

```python
if version == "v1":
    symbols = symbols_v1.symbols
    language_module_map = {"zh": "chinese", "ja": "japanese", "en": "english"}
else:
    symbols = symbols_v2.symbols
    language_module_map = {
        "zh": "chinese2",
        "ja": "japanese",
        "en": "english",
        "ko": "korean",
        "yue": "cantonese",
    }
```

Нужно добавить туда `ru`, например:

```python
language_module_map = {
    "zh": "chinese2",
    "ja": "japanese",
    "en": "english",
    "ko": "korean",
    "yue": "cantonese",
    "ru": "russian",  # <-- новый язык
}
```

И создать модуль `GPT_SoVITS/text/russian.py`.

### 3. Написать простейший `text/russian.py`

Для старта можно сделать **символьный g2p**, где каждая буква — отдельный «фонем»:

```python
# GPT_SoVITS/text/russian.py

import re

# простейшая нормализация
def text_normalize(text: str) -> str:
    text = text.lower()
    text = text.replace("ё", "е")
    # оставляем буквы, пробелы и базовую пунктуацию
    text = re.sub(r"[^а-яa-z0-9 ,.!?\-]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# g2p: возвращаем список "фонем" = символов
def g2p(text: str):
    # можно сделать пробел отдельным символом, например ","
    phones = []
    for ch in text:
        if ch == " ":
            phones.append(",")  # пауза
        else:
            phones.append(ch)
    return phones
```

Это **не идеальная фонетика**, но для первого этапа уже даёт осмысленные токены вместо мусора. Главное — чтобы все эти «фонемы» были перечислены в `symbols.py`.

### 4. Добавить русские символы в `text/symbols.py` / `symbols2.py`

В вики прямо сказано: «нужно добавить фонемы нового языка в symbols.py» ([GitHub][2]).

Открой у себя локально `GPT_SoVITS/text/symbols.py` и/или `symbols2.py` и в список `symbols` добавь:

```python
# пример, добавляем отдельным блоком
_russian_letters = [
    "а","б","в","г","д","е","ж","з","и","й","к","л","м",
    "н","о","п","р","с","т","у","ф","х","ц","ч","ш","щ",
    "ъ","ы","ь","э","ю","я",
]

symbols = [
    # ... здесь уже есть английские символы / служебные токены ...
] + _russian_letters
```

Важно:

* Все «фонемы», которые возвращает `russian.g2p`, **должны присутствовать** в `symbols`, иначе в `clean_text` они превратятся в `UNK`:

  ```python
  phones = ["UNK" if ph not in symbols else ph for ph in phones]
  ```

### 5. Обновить размер словаря фонем в конфиге

В вики ещё один важный пункт: нужно обновить `phoneme_vocab_size` в `GPT_SoVITS/configs/s1longer-v2.yaml` до нового размера `symbols` ([GitHub][2]).

То есть:

1. Посчитать, сколько всего элементов в `symbols`.
2. В конфиге `phoneme_vocab_size: <новое_число>`.

И если ты **обучаешь с нуля**, этого достаточно. Если бы ты дообучал уже готовый базовый s1-модель, надо было бы аккуратно расширять эмбеддинги, но ты как раз собирался учить свою базу.

---

## Что делать прямо сейчас

Если хочешь **минимум телодвижений, чтобы просто пошёл 1Aa-шаг**:

1. В `.list` заменить `|ru|` на `|en|`.
2. (Опционально, но желательно) прогнать тексты через транслитерацию в латиницу.
3. Запустить `1-get-text.py` ещё раз.

Если хочешь **сразу делать всё «по уму» под русский**:

1. Добавить `ru` в `language_v1_to_language_v2` (`1-get-text.py`).
2. Добавить `ru: "russian"` в `language_module_map` (`cleaner.py`).
3. Создать `text/russian.py` с `text_normalize` и `g2p` (можно сначала буквенный вариант, как выше).
4. Добавить русские символы в `symbols.py`/`symbols2.py`.
5. Обновить `phoneme_vocab_size` в конфиге.

Если хочешь, дальше могу помочь тебе:

* набросать конкретный `russian.py` под espeak/phonemizer, чтобы были именно **фонемы**, а не просто буквы;
* написать скрипт, который пробегает по твоему `.list` и автоматически чинит язык/текст.

[1]: https://huggingface.co/kevinwang676/GPT-SoVITS-v-3/blob/21bd603175cfb13c9a189c6028b0878ea9cc5bc1/GPT_SoVITS/prepare_datasets/1-get-text.py "GPT_SoVITS/prepare_datasets/1-get-text.py · kevinwang676/GPT-SoVITS-v-3 at 21bd603175cfb13c9a189c6028b0878ea9cc5bc1"
[2]: https://github.com/RVC-Boss/GPT-SoVITS/wiki/%E8%AE%AD%E7%BB%83%E6%96%B0%E8%AF%AD%E8%A8%80%28how-to-train-the-models-with-other-languages%29 "训练新语言(how to train the models with other languages) · RVC-Boss/GPT-SoVITS Wiki · GitHub"
[3]: https://github.com/RVC-Boss/GPT-SoVITS/raw/main/GPT_SoVITS/text/cleaner.py "raw.githubusercontent.com"
